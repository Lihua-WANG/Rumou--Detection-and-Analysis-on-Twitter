{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"covid-senti-predict.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPygj/weu+ncCh3o+kaO2DJ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4q0rbAmJXOQi","executionInfo":{"status":"ok","timestamp":1620096333131,"user_tz":-600,"elapsed":24218,"user":{"displayName":"LIHUA WANG","photoUrl":"","userId":"14598865299805559806"}},"outputId":"7af8b4fb-aa54-4de6-8720-13691a68b177"},"source":["import pandas as pd\n","import numpy as np\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# open txt file\n","file_object = open('/content/drive/My Drive/data/covid-label.txt')\n","try:\n","    file_content = file_object.read()\n","finally:\n","    file_object.close()\n","# split by \",\"\"\n","result = file_content.split(',')\n","\n","label = []\n","for i in result:\n","   label.append(i)\n","\n","label = list(map(int, label))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"fEAU0EwRXONZ"},"source":["import json\n","import string\n","from keras.preprocessing.text import Tokenizer\n","import pandas as pd\n","import numpy as np\n","import re\n","import nltk\n","import pip\n","from nltk import collections\n","from nltk.tag import pos_tag\n","from nltk.corpus import wordnet\n","from nltk.tokenize import TweetTokenizer\n","from nltk.corpus import stopwords\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn import svm, metrics\n","from sklearn.metrics import precision_recall_fscore_support\n","from nltk.stem import LancasterStemmer, WordNetLemmatizer"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KLJR1llbM128","executionInfo":{"status":"ok","timestamp":1620096337791,"user_tz":-600,"elapsed":28854,"user":{"displayName":"LIHUA WANG","photoUrl":"","userId":"14598865299805559806"}},"outputId":"0e330020-8788-423a-c1cf-ca3240e96f65"},"source":["nltk.download('stopwords')\n","nltk.download('wordnet')\n","\n","# clean data\n","default_stopwords = set(nltk.corpus.stopwords.words('english'))\n","# will have to add the following custom\n","custom_stopwords = {\"http://\", \"rt\", \"co\", \"https://\", \"www\", \"@\"}\n","all_stopwords = default_stopwords | custom_stopwords\n","eng_stemmer = nltk.stem.SnowballStemmer('english')\n","tt = TweetTokenizer()\n","lemmatizer = WordNetLemmatizer()\n","\n","def clean_data(text):\n","    # print(\"Started preprocessing!\")\n","    # text = df['reply_text'].apply(str)\n","    text = re.sub(r'((www\\.[^\\s]+)|(https?://[^\\s]+))', '', text)\n","    text = re.sub(r'@[^\\s]+', '', text)\n","    text = tt.tokenize(text)\n","    # reove single character words\n","    text = [word for word in text if len(word) > 1]\n","    # convert to lower case\n","    text = [word.lower() for word in text]\n","    # removing numbers\n","    text = [word for word in text if not word.isnumeric()]\n","    # stem the words\n","    text = [lemmatizer.lemmatize(word) for word in text]\n","    # remove stopwords\n","    text = [word for word in text if word not in default_stopwords]\n","    text = [word for word in text if nltk.re.match(r\".*[a-z]+.*\", word)]\n","    text = \" \".join(text)\n","    return text"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/wordnet.zip.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TrYpGvwhXOKm","executionInfo":{"status":"ok","timestamp":1620096419986,"user_tz":-600,"elapsed":111034,"user":{"displayName":"LIHUA WANG","photoUrl":"","userId":"14598865299805559806"}},"outputId":"2de0aa8c-206d-4082-8791-99cb3665acf4"},"source":["def process_json_data(read_data_filepath, label):\n","  with open(read_data_filepath, 'r') as f:\n","    source_id = []\n","    source_text = []\n","    reply_text = []\n","    for line in f:\n","      line = json.loads(line)\n","      source_id.append(clean_data(line[0]['id_str']))\n","      source_text.append(clean_data(line[0]['text']))\n","      tmp = []\n","      for i in range(1, len(line)):\n","        tmp.append(clean_data(line[i]['text']))\n","      reply_text.append(tmp)\n","    df_data = pd.DataFrame({'id':source_id,'source_text':source_text, 'reply_text':reply_text, 'label':label})\n","    return df_data[['id', 'source_text', 'reply_text', 'label']]\n","\n","df_covid = process_json_data('/content/drive/My Drive/data/covid.data.jsonl', label)\n","\n","# a list of events, and each event is a list of tweets (source tweet + reactions)\n","print(\"Number of test data =\", len(df_covid[\"source_text\"]))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Number of test data = 17458\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gz3fD3yKFojl","executionInfo":{"status":"ok","timestamp":1620096449210,"user_tz":-600,"elapsed":140238,"user":{"displayName":"LIHUA WANG","photoUrl":"","userId":"14598865299805559806"}},"outputId":"d1a0179a-e066-48a4-9ae8-7767e7466c95"},"source":["!pip install PaddlePaddle\n","import paddle\n","paddle.utils.run_check()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting PaddlePaddle\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/10/e2/1a706d6ce62aae1107c406f1bdd23cf7a6810bc851e04ec9a393deae097b/paddlepaddle-2.0.2-cp37-cp37m-manylinux1_x86_64.whl (168.5MB)\n","\u001b[K     |████████████████████████████████| 168.5MB 87kB/s \n","\u001b[?25hRequirement already satisfied: gast>=0.3.3; platform_system != \"Windows\" in /usr/local/lib/python3.7/dist-packages (from PaddlePaddle) (0.3.3)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from PaddlePaddle) (4.4.2)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from PaddlePaddle) (7.1.2)\n","Requirement already satisfied: numpy>=1.13; python_version >= \"3.5\" and platform_system != \"Windows\" in /usr/local/lib/python3.7/dist-packages (from PaddlePaddle) (1.19.5)\n","Requirement already satisfied: protobuf>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from PaddlePaddle) (3.12.4)\n","Requirement already satisfied: astor in /usr/local/lib/python3.7/dist-packages (from PaddlePaddle) (0.8.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from PaddlePaddle) (1.15.0)\n","Requirement already satisfied: requests>=2.20.0 in /usr/local/lib/python3.7/dist-packages (from PaddlePaddle) (2.23.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.1.0->PaddlePaddle) (56.0.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20.0->PaddlePaddle) (2020.12.5)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20.0->PaddlePaddle) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20.0->PaddlePaddle) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.20.0->PaddlePaddle) (2.10)\n","Installing collected packages: PaddlePaddle\n","Successfully installed PaddlePaddle-2.0.2\n"],"name":"stdout"},{"output_type":"stream","text":["2021-05-04 02:47:28,063 - WARNING - You are using GPU version PaddlePaddle, but there is no GPU detected on your machine. Maybe CUDA devices is not set properly.\n"," Original Error is Not compiled with CUDA\n"],"name":"stderr"},{"output_type":"stream","text":["Running verify PaddlePaddle program ... \n","PaddlePaddle works well on 1 CPU.\n","PaddlePaddle works well on 2 CPUs.\n","PaddlePaddle is installed successfully! Let's start deep learning with PaddlePaddle now.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"K0rhcaf-FocR","executionInfo":{"status":"ok","timestamp":1620096449212,"user_tz":-600,"elapsed":140193,"user":{"displayName":"LIHUA WANG","photoUrl":"","userId":"14598865299805559806"}},"outputId":"870d1db6-5349-43be-8e82-c05b72b25a4c"},"source":["paddle.utils.run_check()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["2021-05-04 02:47:28,150 - WARNING - You are using GPU version PaddlePaddle, but there is no GPU detected on your machine. Maybe CUDA devices is not set properly.\n"," Original Error is Not compiled with CUDA\n"],"name":"stderr"},{"output_type":"stream","text":["Running verify PaddlePaddle program ... \n","PaddlePaddle works well on 1 CPU.\n","PaddlePaddle works well on 2 CPUs.\n","PaddlePaddle is installed successfully! Let's start deep learning with PaddlePaddle now.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"vRNHrbgEFoZ_","executionInfo":{"status":"ok","timestamp":1620096470847,"user_tz":-600,"elapsed":161808,"user":{"displayName":"LIHUA WANG","photoUrl":"","userId":"14598865299805559806"}},"outputId":"0c925270-adce-48a2-e8a4-9921fb8b0e9b"},"source":["!pip install Senta"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting Senta\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a8/d8/8b6a1a2c67405785e0c6d13a13bcb573688403b720bb005acc2863daec03/Senta-2.0.0-py3-none-any.whl (178kB)\n","\u001b[K     |████████████████████████████████| 184kB 5.2MB/s \n","\u001b[?25hCollecting numpy==1.14.5\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3f/e7/7f24ef402a5766c677683e313c5595137d754cb9eb1c99627803280e79d5/numpy-1.14.5-cp37-cp37m-manylinux1_x86_64.whl (12.2MB)\n","\u001b[K     |████████████████████████████████| 12.2MB 18.1MB/s \n","\u001b[?25hCollecting six==1.11.0\n","  Downloading https://files.pythonhosted.org/packages/67/4b/141a581104b1f6397bfa78ac9d43d8ad29a7ca43ea90a2d863fe3056e86a/six-1.11.0-py2.py3-none-any.whl\n","Collecting nltk==3.4.5\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f6/1d/d925cfb4f324ede997f6d47bea4d9babba51b49e87a767c170b77005889d/nltk-3.4.5.zip (1.5MB)\n","\u001b[K     |████████████████████████████████| 1.5MB 42.3MB/s \n","\u001b[?25hCollecting sentencepiece==0.1.83\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e8/cf/7089b87fdae8f47be81ce8e2e6377b321805c4648f2eb12fbd2987388dac/sentencepiece-0.1.83-cp37-cp37m-manylinux1_x86_64.whl (1.0MB)\n","\u001b[K     |████████████████████████████████| 1.0MB 37.4MB/s \n","\u001b[?25hCollecting scikit-learn==0.20.4\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/87/6f/5863f1b27523c5d9f0ae2f3d07828ad383ceab39c79726d2ea4da7f679e7/scikit_learn-0.20.4-cp37-cp37m-manylinux1_x86_64.whl (5.4MB)\n","\u001b[K     |████████████████████████████████| 5.4MB 41.0MB/s \n","\u001b[?25hRequirement already satisfied: scipy>=0.13.3 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.20.4->Senta) (1.4.1)\n","Building wheels for collected packages: nltk\n","  Building wheel for nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for nltk: filename=nltk-3.4.5-cp37-none-any.whl size=1449906 sha256=54783a9f883ab17c90320edf266abd0c748ed94feee588c1a9aecb42145a47ee\n","  Stored in directory: /root/.cache/pip/wheels/96/86/f6/68ab24c23f207c0077381a5e3904b2815136b879538a24b483\n","Successfully built nltk\n","\u001b[31mERROR: xarray 0.15.1 has requirement numpy>=1.15, but you'll have numpy 1.14.5 which is incompatible.\u001b[0m\n","\u001b[31mERROR: tifffile 2021.4.8 has requirement numpy>=1.15.1, but you'll have numpy 1.14.5 which is incompatible.\u001b[0m\n","\u001b[31mERROR: tensorflow 2.4.1 has requirement numpy~=1.19.2, but you'll have numpy 1.14.5 which is incompatible.\u001b[0m\n","\u001b[31mERROR: tensorflow 2.4.1 has requirement six~=1.15.0, but you'll have six 1.11.0 which is incompatible.\u001b[0m\n","\u001b[31mERROR: spacy 2.2.4 has requirement numpy>=1.15.0, but you'll have numpy 1.14.5 which is incompatible.\u001b[0m\n","\u001b[31mERROR: seaborn 0.11.1 has requirement numpy>=1.15, but you'll have numpy 1.14.5 which is incompatible.\u001b[0m\n","\u001b[31mERROR: pyerfa 1.7.2 has requirement numpy>=1.16, but you'll have numpy 1.14.5 which is incompatible.\u001b[0m\n","\u001b[31mERROR: pyarrow 3.0.0 has requirement numpy>=1.16.6, but you'll have numpy 1.14.5 which is incompatible.\u001b[0m\n","\u001b[31mERROR: plotnine 0.6.0 has requirement numpy>=1.16.0, but you'll have numpy 1.14.5 which is incompatible.\u001b[0m\n","\u001b[31mERROR: pandas 1.1.5 has requirement numpy>=1.15.4, but you'll have numpy 1.14.5 which is incompatible.\u001b[0m\n","\u001b[31mERROR: numba 0.51.2 has requirement numpy>=1.15, but you'll have numpy 1.14.5 which is incompatible.\u001b[0m\n","\u001b[31mERROR: librosa 0.8.0 has requirement numpy>=1.15.0, but you'll have numpy 1.14.5 which is incompatible.\u001b[0m\n","\u001b[31mERROR: jaxlib 0.1.65+cuda110 has requirement numpy>=1.16, but you'll have numpy 1.14.5 which is incompatible.\u001b[0m\n","\u001b[31mERROR: imgaug 0.2.9 has requirement numpy>=1.15.0, but you'll have numpy 1.14.5 which is incompatible.\u001b[0m\n","\u001b[31mERROR: google-colab 1.0.0 has requirement six~=1.15.0, but you'll have six 1.11.0 which is incompatible.\u001b[0m\n","\u001b[31mERROR: google-api-python-client 1.12.8 has requirement six<2dev,>=1.13.0, but you'll have six 1.11.0 which is incompatible.\u001b[0m\n","\u001b[31mERROR: google-api-core 1.26.3 has requirement six>=1.13.0, but you'll have six 1.11.0 which is incompatible.\u001b[0m\n","\u001b[31mERROR: fbprophet 0.7.1 has requirement numpy>=1.15.4, but you'll have numpy 1.14.5 which is incompatible.\u001b[0m\n","\u001b[31mERROR: fastai 1.0.61 has requirement numpy>=1.15, but you'll have numpy 1.14.5 which is incompatible.\u001b[0m\n","\u001b[31mERROR: dm-tree 0.1.6 has requirement six>=1.12.0, but you'll have six 1.11.0 which is incompatible.\u001b[0m\n","\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n","\u001b[31mERROR: cvxpy 1.0.31 has requirement numpy>=1.15, but you'll have numpy 1.14.5 which is incompatible.\u001b[0m\n","\u001b[31mERROR: blis 0.4.1 has requirement numpy>=1.15.0, but you'll have numpy 1.14.5 which is incompatible.\u001b[0m\n","\u001b[31mERROR: astropy 4.2.1 has requirement numpy>=1.17, but you'll have numpy 1.14.5 which is incompatible.\u001b[0m\n","\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n","Installing collected packages: numpy, six, nltk, sentencepiece, scikit-learn, Senta\n","  Found existing installation: numpy 1.19.5\n","    Uninstalling numpy-1.19.5:\n","      Successfully uninstalled numpy-1.19.5\n","  Found existing installation: six 1.15.0\n","    Uninstalling six-1.15.0:\n","      Successfully uninstalled six-1.15.0\n","  Found existing installation: nltk 3.2.5\n","    Uninstalling nltk-3.2.5:\n","      Successfully uninstalled nltk-3.2.5\n","  Found existing installation: scikit-learn 0.22.2.post1\n","    Uninstalling scikit-learn-0.22.2.post1:\n","      Successfully uninstalled scikit-learn-0.22.2.post1\n","Successfully installed Senta-2.0.0 nltk-3.4.5 numpy-1.14.5 scikit-learn-0.20.4 sentencepiece-0.1.83 six-1.11.0\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["nltk","numpy","six","sklearn"]}}},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"ov7CFiI1FoXZ"},"source":["from senta import Senta"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3BzbogPzFoUr","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620096470856,"user_tz":-600,"elapsed":161796,"user":{"displayName":"LIHUA WANG","photoUrl":"","userId":"14598865299805559806"}},"outputId":"d9682add-9da3-4ed5-e054-6873287c5b82"},"source":["my_senta = Senta()\n","\n","# 获取目前支持的情感预训练模型, 我们开放了以ERNIE 1.0 large(中文)、ERNIE 2.0 large(英文)和RoBERTa large(英文)作为初始化的SKEP模型\n","print(my_senta.get_support_model()) # [\"ernie_1.0_skep_large_ch\", \"ernie_2.0_skep_large_en\", \"roberta_skep_large_en\"]\n","\n","# 获取目前支持的预测任务\n","print(my_senta.get_support_task()) # [\"sentiment_classify\", \"aspect_sentiment_classify\", \"extraction\"]\n","\n","# 选择是否使用gpu\n","use_cuda = False # 设置True or False"],"execution_count":null,"outputs":[{"output_type":"stream","text":["['ernie_1.0_skep_large_ch', 'ernie_2.0_skep_large_en', 'roberta_skep_large_en']\n","['sentiment_classify', 'aspect_sentiment_classify', 'extraction']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"jBC6LKiRm2nV"},"source":["my_senta.init_model(model_class=\"roberta_skep_large_en\", task=\"sentiment_classify\", use_cuda=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aY8_Z9_Jm2fI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620096620188,"user_tz":-600,"elapsed":311083,"user":{"displayName":"LIHUA WANG","photoUrl":"","userId":"14598865299805559806"}},"outputId":"023fac83-685d-432e-d18f-b5228ad73d03"},"source":["texts = [\"a perfect film\"]\n","result = my_senta.predict(texts)\n","print(result)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[('a perfect film', 'positive')]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"jxRfQXc4LWdf"},"source":["source_data = df_covid['source_text'].values.tolist()\n","# type(source_data)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Kqem-cfjm2Xz","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620109337779,"user_tz":-600,"elapsed":33132,"user":{"displayName":"LIHUA WANG","photoUrl":"","userId":"14598865299805559806"}},"outputId":"6b32dd6d-26d2-460d-f461-067058986908"},"source":["source_senti = []\n","tmpList = []\n","j = 17400\n","while j < 17459:\n","  source_senti = []\n","  tmpList = source_data[j:(j+100)]\n","  tmp = my_senta.predict(tmpList)\n","  for i in tmp:\n","    source_senti.append(1 if i[1] == 'positive' else 0)\n","  df = pd.DataFrame(source_senti)\n","  df.to_csv(\"/content/drive/My Drive/data/source_senti.csv\", mode='a', index=False, header=False)\n","  # df.to_csv(\"source_senti.csv\", mode='a', index=False, header=False)\n","  j += 100\n","  print(j)\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["17500\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"IUi6RhTQm2Oa"},"source":["# df = pd.DataFrame(source_senti)\n","# df.to_csv('source_senti.csv', index=False, heder=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nK2eHi_jm2Fn"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JNU_nXvdm17p"},"source":[""],"execution_count":null,"outputs":[]}]}